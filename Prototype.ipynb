{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import splev\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "sns.set(font_scale=1.5)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = pd.read_csv(\"Group10_CGAnnote_Phase1_Ref.csv\")\n",
    "segments = pd.read_csv(\"Group_10/Group_10_CPS.csv\")\n",
    "seg_com = segments.copy().iloc[:,:4]\n",
    "seg_com[[\"Observation\", \"Statement\", \"Accept\", \"Doubt\", \"Question\", \"Recommendation\"]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr = 0\n",
    "for i in range(com.shape[0]):\n",
    "    start, end = float(com.iloc[i, 0]), float(com.iloc[i, 1])\n",
    "    while True:\n",
    "        if start > float(seg_com.iloc[ptr, 2]) or (float(seg_com.iloc[ptr, 2]) - start) < (end - seg_com.iloc[min(ptr+1, seg_com.shape[0]-1), 1]):\n",
    "            ptr += 1\n",
    "        else:\n",
    "            if end < seg_com.iloc[ptr, 1]:\n",
    "                utterance_id = ptr + 1000\n",
    "            else:\n",
    "                utterance_id = ptr\n",
    "            break\n",
    "    com.at[i, \"Utterance_id\"] = int(utterance_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Begin Time - ss.msec</th>\n",
       "      <th>End Time - ss.msec</th>\n",
       "      <th>Duration - ss.msec</th>\n",
       "      <th>test-common ground</th>\n",
       "      <th>Utterance_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.431</td>\n",
       "      <td>27.450</td>\n",
       "      <td>4.019</td>\n",
       "      <td>S0: STATEMENT(red =10)</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.294</td>\n",
       "      <td>56.862</td>\n",
       "      <td>1.568</td>\n",
       "      <td>S1:  STATEMENT(red =10)</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.882</td>\n",
       "      <td>58.647</td>\n",
       "      <td>1.765</td>\n",
       "      <td>ACCEPT(S1) FACT += (red =10)</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.666</td>\n",
       "      <td>65.294</td>\n",
       "      <td>4.628</td>\n",
       "      <td>R1: RECOMMENDATION(bigger ones?) QUD += bigger...</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.274</td>\n",
       "      <td>72.725</td>\n",
       "      <td>1.451</td>\n",
       "      <td>O1: OBSERVATION: on(RedBlock and BlueBlock, Le...</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Begin Time - ss.msec  End Time - ss.msec  Duration - ss.msec  \\\n",
       "0                23.431              27.450               4.019   \n",
       "1                55.294              56.862               1.568   \n",
       "2                56.882              58.647               1.765   \n",
       "3                60.666              65.294               4.628   \n",
       "4                71.274              72.725               1.451   \n",
       "\n",
       "                                  test-common ground  Utterance_id  \n",
       "0                             S0: STATEMENT(red =10)           3.0  \n",
       "1                            S1:  STATEMENT(red =10)          12.0  \n",
       "2                      ACCEPT(S1) FACT += (red =10)           12.0  \n",
       "3  R1: RECOMMENDATION(bigger ones?) QUD += bigger...          14.0  \n",
       "4  O1: OBSERVATION: on(RedBlock and BlueBlock, Le...          17.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(com.shape[0]):\n",
    "    idx = int(com.iloc[i][\"Utterance_id\"])\n",
    "    if \"OBSERVATION\" in com.iloc[i][\"test-common ground\"]:\n",
    "        seg_com.at[idx, \"Observation\"] = 1\n",
    "    elif \"STATEMENT\" in com.iloc[i][\"test-common ground\"]:\n",
    "        seg_com.at[idx, \"Statement\"] = 1\n",
    "    elif \"ACCEPT\" in com.iloc[i][\"test-common ground\"]:\n",
    "        seg_com.at[idx, \"Accept\"] = 1\n",
    "    elif \"DOUBT\" in com.iloc[i][\"test-common ground\"]:\n",
    "        seg_com.at[idx, \"Doubt\"] = 1\n",
    "    elif \"QUESTION\" in com.iloc[i][\"test-common ground\"]:\n",
    "        seg_com.at[idx, \"Question\"] = 1\n",
    "    elif \"RECOMMENNDATION\" in com.iloc[i][\"test-common ground\"]:\n",
    "        seg_com.at[idx, \"Recommendation\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Group</th>\n",
       "      <th>Observation</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Doubt</th>\n",
       "      <th>Question</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>9.60</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14.67</td>\n",
       "      <td>19.08</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19.71</td>\n",
       "      <td>22.41</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24.27</td>\n",
       "      <td>27.03</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>27.60</td>\n",
       "      <td>30.24</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>868.71</td>\n",
       "      <td>871.92</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>875.31</td>\n",
       "      <td>878.91</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>881.04</td>\n",
       "      <td>889.65</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>889.74</td>\n",
       "      <td>892.77</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>892.89</td>\n",
       "      <td>895.20</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Utterance   Start     End  Group  Observation  Statement  Accept  Doubt  \\\n",
       "0            0    4.02    9.60     10            0          0       0      0   \n",
       "1            1   14.67   19.08     10            0          0       0      0   \n",
       "2            2   19.71   22.41     10            0          0       0      0   \n",
       "3            3   24.27   27.03     10            0          1       0      0   \n",
       "4            4   27.60   30.24     10            0          0       0      0   \n",
       "..         ...     ...     ...    ...          ...        ...     ...    ...   \n",
       "141        141  868.71  871.92     10            0          0       0      0   \n",
       "142        142  875.31  878.91     10            0          0       0      0   \n",
       "143        143  881.04  889.65     10            0          0       0      0   \n",
       "144        144  889.74  892.77     10            0          0       0      0   \n",
       "145        145  892.89  895.20     10            0          0       0      0   \n",
       "\n",
       "     Question  Recommendation  \n",
       "0           0               0  \n",
       "1           0               0  \n",
       "2           0               0  \n",
       "3           0               0  \n",
       "4           0               0  \n",
       "..        ...             ...  \n",
       "141         0               0  \n",
       "142         0               0  \n",
       "143         0               0  \n",
       "144         0               0  \n",
       "145         0               0  \n",
       "\n",
       "[146 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Observation        5\n",
       "Statement         12\n",
       "Accept            11\n",
       "Doubt              1\n",
       "Question           0\n",
       "Recommendation     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_com.iloc[:, 4:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_com.to_csv(\"Group_10/Group_10_CG.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataset = [[], []]\n",
    "        self.targets = []\n",
    "\n",
    "    def openBERT(self,filename):\n",
    "        data=pd.read_csv(filename, names=[\"index\", \"embed\"])\n",
    "        data.sort_values(by='index',inplace=True)\n",
    "        for index, row in data.iterrows():\n",
    "            try:\n",
    "                tensor=np.asarray(row[1].replace(',','.').split('[[')[1].split(']]')[0].split(),dtype=np.float32).tolist()\n",
    "            except:\n",
    "                print('problem with utterance number ',row[0])\n",
    "                tensor=self.dataset[0][-1]\n",
    "            self.dataset[0].append(tensor)\n",
    "            \n",
    "    \n",
    "    def openSmile(self,filename):\n",
    "        data=pd.read_csv(filename)\n",
    "        for i in range (data.shape[0]):\n",
    "            row=data[data['file']==f'D:\\\\Research\\\\Weights_Task\\\\Weights_Task_Audio\\\\{filename[filename.index(\"Group_\"):filename.index(\"Group_\")+8]}-audio_PCM\\\\segments\\\\{filename[filename.index(\"Group_\"):filename.index(\"Group_\")+8]}-audio_PCM_'+str(i)+'.wav']\n",
    "            tensor=np.asarray(row.values[0][3:],dtype=np.float32).tolist()\n",
    "            self.dataset[1].append(tensor)\n",
    "        \n",
    "\n",
    "    def openTarget(self,filename):\n",
    "        data=pd.read_csv(filename)\n",
    "        for row in range(data.shape[0]):\n",
    "            target = data.iloc[row, 4:].values.astype(int)\n",
    "            self.targets.append(target)\n",
    "\n",
    "\n",
    "    def get_datasets(self):\n",
    "        final_dataset=[]\n",
    "        for bert,opensmile,label in zip(self.dataset[0],self.dataset[1],self.targets):\n",
    "            final_dataset.append([bert,opensmile,label])\n",
    "        random.shuffle(final_dataset)\n",
    "        return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataset, root, file):\n",
    "    if 'bert' in file:\n",
    "        dataset.openBERT(root+\"/\"+file)\n",
    "    elif 'features' in file:\n",
    "        dataset.openSmile(root+\"/\"+file)\n",
    "    elif 'CG' in file:\n",
    "        dataset.openTarget(root+\"/\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = DATA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs,files in (os.walk(os. getcwd())):\n",
    "    if \"Group_10\" in root:\n",
    "        for file in files:\n",
    "            read_data(train_datasets, root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nlp_dataset(Dataset):\n",
    "    def __init__(self,xy=None):\n",
    "\n",
    "        self.bert_data = torch.from_numpy(np.asarray([el[0] for el in xy ],dtype=np.float32))\n",
    "        self.open_data = torch.from_numpy(np.asarray([el[1] for el in xy ],dtype=np.float32))\n",
    "        self.y_data = torch.from_numpy(np.asarray([el[2] for el in xy ],dtype=np.float32))\n",
    "        self.len=len(self.bert_data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.bert_data[index], self.open_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=nlp_dataset(train_datasets.get_datasets()),batch_size=16,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class common_ground(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(common_ground, self).__init__()\n",
    "        self.lin_bert = nn.Linear(512, 256)\n",
    "        self.lin_open = nn.Linear(88, 256)\n",
    "        self.ff = nn.Linear(512, 512)\n",
    "        self.classifier = nn.Linear(512, 1)\n",
    "    \n",
    "    def forward(self, bert, opensmile):\n",
    "        bert = self.lin_bert(bert)\n",
    "        opensmile = self.lin_open(opensmile)\n",
    "        x = torch.hstack((bert, opensmile))\n",
    "        x = self.ff(x)\n",
    "        predict = self.classifier(x)\n",
    "\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, total_epochs, train_iterator, class_to_eval):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    nepochs = 0\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCELoss(reduction='mean').to(device)\n",
    "    while nepochs < total_epochs :\n",
    "        optimizer.zero_grad()\n",
    "        for batch_idx, (bert_data, open_data, target) in enumerate(train_iterator):\n",
    "            output = model(bert_data.to(device), open_data.to(device))\n",
    "            target_binary = torch.zeros(target.size()[0], 1).to(device)\n",
    "            for i,t in enumerate(target):\n",
    "                target_binary[i] = torch.Tensor([t[class_to_eval]])\n",
    "            loss = criterion(torch.sigmoid(output).to(device), target_binary)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        nepochs += 1\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_iterator, class_to_eval):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        true, pred = None, None\n",
    "        for batch_idx, (bert_data, open_data, target) in enumerate(test_iterator):\n",
    "            output = model(bert_data.to(device), open_data.to(device))\n",
    "            pred_tmp = torch.sigmoid(output)\n",
    "            true_binary = torch.zeros(target.size()[0], 1)\n",
    "            for i, t in enumerate(target):\n",
    "                true_binary[i] = torch.Tensor([t[class_to_eval]])\n",
    "            \n",
    "            if true == None:\n",
    "                true = true_binary\n",
    "                pred = pred_tmp > 0.5\n",
    "                pred_probs = pred_tmp\n",
    "\n",
    "            else :\n",
    "                true = torch.cat((true, true_binary))\n",
    "                pred = torch.cat((pred, pred_tmp > 0.5))\n",
    "                pred_probs = torch.cat((pred_probs, pred_tmp))\n",
    "    return true, pred, pred_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_eval = 1\n",
    "model = common_ground().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_ground(\n",
       "  (lin_bert): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (lin_open): Linear(in_features=88, out_features=256, bias=True)\n",
       "  (ff): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (classifier): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, 20, train_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test(model, train_loader, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-folds\n",
    "# get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [train_datasets.get_datasets()[x:x+30] for x in range(0, len(train_datasets.get_datasets()), 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03333333333333333\n",
      "0.03333333333333333\n",
      "0.03333333333333333\n",
      "0.9\n",
      "0.0\n",
      "0.03333333333333333\n",
      "0.9333333333333333\n",
      "0.03333333333333333\n",
      "0.06666666666666667\n",
      "1.0\n",
      "0.03333333333333333\n",
      "0.9\n",
      "1.0\n",
      "0.13333333333333333\n",
      "0.9615384615384616\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for class_to_eval in range(5):\n",
    "    for k in range(len(folds)):\n",
    "        train_l = []\n",
    "        for i in range(len(folds)):\n",
    "            if i != k:\n",
    "                train_l += folds[i]\n",
    "        test_l = folds[k]\n",
    "        train_loader = DataLoader(dataset=nlp_dataset(train_l),batch_size=16,shuffle=False)\n",
    "        test_loader = DataLoader(dataset=nlp_dataset(test_l),batch_size=16,shuffle=False)\n",
    "        model = common_ground().to(device)\n",
    "        train(model, 20, train_loader, class_to_eval)\n",
    "        true, pred, pred_probs = test(model, test_loader, class_to_eval)\n",
    "        # try:\n",
    "        #     auroc = roc_auc_score(true, torch.nan_to_num(pred_probs, 0))\n",
    "        # except:\n",
    "        #     auroc =  0\n",
    "        # print(auroc)\n",
    "        accuracy = accuracy_score(true.to(\"cpu\"), pred.to(\"cpu\"))\n",
    "        print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
