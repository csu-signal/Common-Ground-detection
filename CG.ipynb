{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import shap\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, XLMTokenizer, XLMConfig, XLMModel, \\\n",
    "    AlbertTokenizer, AlbertModel, RobertaTokenizer, RobertaConfig, RobertaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM = \"bert-base-uncased\"\n",
    "# LLM = \"bert-large-uncased\"\n",
    "# LLM = \"albert\"\n",
    "LLM = \"roberta\"\n",
    "# LLM = \"xlm\"\n",
    "\n",
    "def change_llm(LLM):\n",
    "\n",
    "    if \"bert-\" in LLM:\n",
    "        tokenizer = BertTokenizer.from_pretrained(LLM)\n",
    "        llm = BertModel.from_pretrained(LLM)\n",
    "\n",
    "\n",
    "    if LLM == \"albert\":\n",
    "        tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "        llm = AlbertModel.from_pretrained('albert-base-v2')\n",
    "\n",
    "    if LLM == \"roberta\":\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "        configuration = RobertaConfig()\n",
    "        llm = RobertaModel(configuration)\n",
    "\n",
    "    if LLM == \"xlm\":\n",
    "        tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-en-2048\")\n",
    "        configuration = XLMConfig()\n",
    "        llm = XLMModel(configuration)\n",
    "\n",
    "\n",
    "    llm.eval()\n",
    "    sentence = \"Paris is a beautiful city\" \n",
    "    tok = tokenizer(sentence)\n",
    "    encoded_layers = llm(torch.Tensor([tok.input_ids]).to(torch.int), attention_mask=torch.Tensor([tok.attention_mask]))\n",
    "    llm_size = (encoded_layers.last_hidden_state)[:, 0, :].size()[1]\n",
    "\n",
    "    return tokenizer, llm, llm_size\n",
    "tokenizer, llm, llm_size = change_llm(LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv1_lv3 = dict({0:0, 1:0, 2:0, 3:0, 4:0, 5:1, 6:1, 7:1, 8:1, 9:1, 10:1, 11:1, 12:1, 13:2, 14:2, 15:2, 16:2, 17:2, 18:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataset_llm = []\n",
    "        self.dataset_opensmile = []\n",
    "        self.dataset_cps_f = []\n",
    "        self.dataset_cps_i = []\n",
    "        self.dataset_action = []\n",
    "        self.dataset_gamr = []\n",
    "\n",
    "        self.targets = []\n",
    "\n",
    "    def openLLM(self, filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        for i in range(len(data)):\n",
    "            self.dataset_llm.append(np.asarray(data.iloc[i]).tolist())\n",
    "    \n",
    "    \n",
    "    def openSmile(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        for i in range (data.shape[0]):\n",
    "            # print(f'C:\\\\Users\\\\Bbykitty\\\\OneDrive - Colostate\\\\Research\\\\Initial Observations for Fib Weights\\\\Data\\\\Segment Analysis\\\\{filename[filename.index(\"Group_\"):filename.index(\"Group_\")+8]}\\\\segments_oracle\\\\{filename[filename.index(\"Group_\"):filename.index(\"Group_\")+8]}_'+str(i)+'.wav')\n",
    "            row=data[data['file']==f'C:\\\\Users\\\\bradf\\\\OneDrive - Colostate\\\\Research\\\\Initial Observations for Fib Weights\\\\Data\\\\Segment Analysis\\\\{filename[filename.index(\"Group_\"):filename.index(\"Group_\")+8]}\\\\segments_oracle\\\\{filename[filename.index(\"Group_\"):filename.index(\"Group_\")+8]}_'+str(i)+'.wav']\n",
    "            tensor=np.nan_to_num(np.asarray(row.values[0][3:91],dtype=np.float32)).tolist()\n",
    "            self.dataset_opensmile.append(tensor)\n",
    "\n",
    "\n",
    "    def openCPS(self, filename):\n",
    "        data = pd.read_csv(filename).fillna(0)\n",
    "        for row in range(data.shape[0]):\n",
    "            cps = data.iloc[row, 8:].fillna(0)\n",
    "            self.dataset_cps_i.append(list(cps.values))\n",
    "            cps_f = [0, 0, 0]\n",
    "            for i, c in enumerate(list(cps.values)):\n",
    "                if c == 1:\n",
    "                    cps_f[lv1_lv3[i]] = 1\n",
    "            self.dataset_cps_f.append(cps_f)\n",
    "\n",
    "    def openAction(self, filename):\n",
    "        data = pd.read_csv(filename, header=None).fillna(0)\n",
    "        for row in range(data.shape[0]):\n",
    "            self.dataset_action.append(data.iloc[row].to_list())\n",
    "\n",
    "\n",
    "\n",
    "    def openGAMR(self, filename):\n",
    "        data = pd.read_csv(filename, header=None).fillna(0)\n",
    "        for row in range(data.shape[0]):\n",
    "            self.dataset_gamr.append(data.iloc[row].to_list())\n",
    "        \n",
    "\n",
    "    def openTarget(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        for row in range(data.shape[0]):\n",
    "            target = data.iloc[row, 3:].values.astype(int)\n",
    "            self.targets.append(target.tolist())\n",
    "\n",
    "\n",
    "    def get_datasets(self, rand=False):\n",
    "        final_dataset=[]        \n",
    "        for llm, opensmile, cps_f, cps_i, action, gamr, label in zip(self.dataset_llm, self.dataset_opensmile,self.dataset_cps_f, self.dataset_cps_i, self.dataset_action, self.dataset_gamr, self.targets):\n",
    "            final_dataset.append([llm, opensmile, cps_f, cps_i, action, gamr, label])\n",
    "            \n",
    "        if rand:\n",
    "            random.shuffle(final_dataset)\n",
    "        return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataset, root, file, llm=\"bert-base-uncased\"):\n",
    "\n",
    "    if LLM in file:\n",
    "        dataset.openLLM(root+\"/\"+file)\n",
    "    if 'oracle_opensmile' in file:\n",
    "        dataset.openSmile(root+\"/\"+file)\n",
    "    elif 'CPS_Oracle' in file:\n",
    "        dataset.openCPS(root+\"/\"+file)\n",
    "    elif \"Actions_Oracle_vectors\" in file:\n",
    "        dataset.openAction(root+\"/\"+file)\n",
    "    elif \"GAMR_Oracle_vectors\" in file:\n",
    "        dataset.openGAMR(root+\"/\"+file)\n",
    "    elif 'CG.csv' in file:\n",
    "        dataset.openTarget(root+\"/\"+file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = DATA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/s/chopin/b/grad/benkh/Common Ground/Group_05\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/s/chopin/b/grad/benkh/Common Ground/Group_06\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_02\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_09\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_03\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_10\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_08\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_01\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_04\n"
     ]
    }
   ],
   "source": [
    "for root, dirs,files in (os.walk(os. getcwd())):\n",
    "    if \"Group_\" in root and \"data\" not in root:\n",
    "        if \"asr\" not in root:\n",
    "            print(root)\n",
    "            for file in files:\n",
    "                read_data(train_datasets, root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_datasets.dataset_llm) == len(train_datasets.dataset_opensmile) == len(train_datasets.dataset_cps_f) == len(train_datasets.dataset_cps_i) == len(train_datasets.dataset_action) == len(train_datasets.dataset_gamr) == len(train_datasets.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# train_datasets.dataset_llm = scaler.fit_transform(train_datasets.dataset_llm).tolist()\n",
    "# scaler = MinMaxScaler()\n",
    "# train_datasets.dataset_opensmile = scaler.fit_transform(train_datasets.dataset_opensmile).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  52,   62,   88,   65,    4,    0,   18, 2584])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.asarray(train_datasets.targets), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.asarray(train_datasets.targets), axis=0)[:-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2873"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.asarray(train_datasets.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to check if any utterance has more than 1 CGA\n",
    "\n",
    "# d = dict()\n",
    "# l = []\n",
    "# for utt_id, utt in enumerate(train_datasets.targets):\n",
    "#     if np.sum(utt) > 1:\n",
    "#         d[utt_id] = np.sum(utt)\n",
    "#         l.append(utt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rec_dataset(Dataset):\n",
    "    def __init__(self,xy=None, window_size=3):\n",
    "        self.utt_bert_l = []\n",
    "        self.utt_open_l = []\n",
    "        self.utt_cps_f_l = []\n",
    "        self.utt_cps_i_l = []\n",
    "        self.utt_action_l = []\n",
    "        self.utt_gamr_l = []\n",
    "        self.utt_y_l = []\n",
    "        self.utt_y = []\n",
    "\n",
    "        for utt in xy:\n",
    "            bert_tmp = []\n",
    "            open_tmp = []\n",
    "            cps_i_tmp = []\n",
    "            cps_f_tmp = []\n",
    "            action_tmp = []\n",
    "            gamr_tmp = []\n",
    "            y_tmp = []\n",
    "            for utt_id in range(window_size+1):\n",
    "                bert_tmp.append(utt[utt_id][0][:llm_size])\n",
    "                open_tmp.append(utt[utt_id][0][llm_size:llm_size+88])\n",
    "                cps_i_tmp.append(utt[utt_id][0][llm_size+88:llm_size+88+19])\n",
    "                cps_f_tmp.append(utt[utt_id][0][llm_size+88+19:llm_size+88+19+3])\n",
    "                action_tmp.append(utt[utt_id][0][llm_size+88+19+3:llm_size+88+19+3+78])\n",
    "                gamr_tmp.append(utt[utt_id][0][llm_size+88+19+3+78:])\n",
    "                y_tmp.append(utt[utt_id][1])\n",
    "            self.utt_bert_l.append(bert_tmp)\n",
    "            self.utt_open_l.append(open_tmp)\n",
    "            self.utt_cps_f_l.append(cps_f_tmp)\n",
    "            self.utt_cps_i_l.append(cps_i_tmp)\n",
    "            self.utt_action_l.append(action_tmp)\n",
    "            self.utt_gamr_l.append(gamr_tmp)\n",
    "            self.utt_y_l.append(y_tmp)\n",
    "        self.utt_bert_l = torch.from_numpy(np.asarray(self.utt_bert_l,dtype=np.float32))\n",
    "        self.utt_open_l = torch.from_numpy(np.asarray(self.utt_open_l,dtype=np.float32))\n",
    "        self.utt_cps_f_l = torch.from_numpy(np.asarray(self.utt_cps_f_l,dtype=np.float32))\n",
    "        self.utt_cps_i_l = torch.from_numpy(np.asarray(self.utt_cps_i_l,dtype=np.float32))\n",
    "        self.utt_action_l = torch.from_numpy(np.asarray(self.utt_action_l,dtype=np.float32))\n",
    "        self.utt_gamr_l = torch.from_numpy(np.asarray(self.utt_gamr_l,dtype=np.float32))\n",
    "        self.utt_y_l = torch.from_numpy(np.asarray(self.utt_y_l,dtype=np.float32))\n",
    "\n",
    "        for utt_id in range(len(self.utt_y_l)):\n",
    "            self.utt_y.append(self.utt_y_l[utt_id][-1])\n",
    "\n",
    "        self.len=len(self.utt_bert_l)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.utt_bert_l[index], self.utt_open_l[index], self.utt_cps_f_l[index], self.utt_cps_i_l[index], self.utt_action_l[index], self.utt_gamr_l[index], self.utt_y_l[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rec_common_ground(nn.Module):\n",
    "    def __init__(self, lin_layers=True, bert_b=True, opensmile_b=True, cps_b=True, cps_f_b=True, action_b=True, gamr_b=True, output_size=1):\n",
    "        super(rec_common_ground, self).__init__()\n",
    "        self.lin_bert1 = nn.Linear(llm_size, 256)\n",
    "        self.lin_bert2 = nn.Linear(256, 256)\n",
    "        self.lstm_bert = nn.LSTM(input_size=256, batch_first=True, hidden_size=256)\n",
    "        if not lin_layers:\n",
    "            self.lstm_bert = nn.LSTM(input_size=llm_size, batch_first=True, hidden_size=256)\n",
    "\n",
    "\n",
    "        self.lin_open1 = nn.Linear(88, 256)\n",
    "        self.lin_open2 = nn.Linear(256, 256)\n",
    "        self.lstm_opensmile = nn.LSTM(input_size=256, batch_first=True, hidden_size=256)\n",
    "        if not lin_layers:\n",
    "            self.lstm_opensmile = nn.LSTM(input_size=88, batch_first=True, hidden_size=256)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        cps_size = 19\n",
    "        if cps_f_b:\n",
    "            cps_size = 3\n",
    "        self.lin_cps1 = nn.Linear(cps_size, 256)\n",
    "        self.lin_cps2 = nn.Linear(256, 256)\n",
    "        self.lstm_cps = nn.LSTM(input_size=256, batch_first=True, hidden_size=256)\n",
    "        if not lin_layers:\n",
    "            self.lstm_cps = nn.LSTM(input_size=cps_size, batch_first=True, hidden_size=256)\n",
    "\n",
    "\n",
    "        self.lin_action1 = nn.Linear(78, 256)\n",
    "        self.lin_action2 = nn.Linear(256, 256)\n",
    "        self.lstm_action = nn.LSTM(input_size=256, batch_first=True, hidden_size=256)\n",
    "        if not lin_layers:\n",
    "            self.lstm_action = nn.LSTM(input_size=78, batch_first=True, hidden_size=256)\n",
    "\n",
    "        self.lin_gamr1 = nn.Linear(243, 256)\n",
    "        self.lin_gamr2 = nn.Linear(256, 256)\n",
    "        self.lstm_gamr = nn.LSTM(input_size=256, batch_first=True, hidden_size=256)\n",
    "        if not lin_layers:\n",
    "            self.lstm_gamr = nn.LSTM(input_size=243, batch_first=True, hidden_size=256)\n",
    "\n",
    "\n",
    "\n",
    "        n_modals = int(bert_b) + int(opensmile_b) + int(cps_b) + int(action_b) + int(gamr_b)\n",
    "        self.ff1 = nn.Linear(256*n_modals, 512)\n",
    "        self.ff2 = nn.Linear(512, 512)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.act2 = nn.SiLU()\n",
    "        self.classifier = nn.Linear(512, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, utt_bert_l, utt_open_l, utt_cps_l, utt_action_l, utt_gamr_l, lin_layers=True, bert_b=True, opensmile_b=True, cps_b=True, cps_f_b=True, action_b=True, gamr_b=True):\n",
    "\n",
    "        if bert_b:\n",
    "            if lin_layers:\n",
    "                utt_bert_l = [self.lin_bert1(utt_x_bert) for utt_x_bert in utt_bert_l]\n",
    "                utt_bert_l = [self.lin_bert2(utt_x_bert) for utt_x_bert in utt_bert_l]\n",
    "                utt_bert_l = [self.relu(utt_x_bert) for utt_x_bert in utt_bert_l]\n",
    "            bert = torch.stack(tuple(utt_bert_l), dim=1)\n",
    "            bert = self.lstm_bert(bert)[1][0][0]\n",
    "\n",
    "        if opensmile_b:\n",
    "            if lin_layers:\n",
    "                utt_open_l = [self.lin_open1(utt_x_open) for utt_x_open in utt_open_l]\n",
    "                utt_open_l = [self.lin_open2(utt_x_open) for utt_x_open in utt_open_l]\n",
    "                utt_open_l = [self.relu(utt_x_open) for utt_x_open in utt_open_l]\n",
    "            opensmile = torch.stack(tuple(utt_open_l), dim=1)\n",
    "            opensmile = self.lstm_opensmile(opensmile)[1][0][0]\n",
    "\n",
    "        if cps_b:\n",
    "            if lin_layers:\n",
    "                utt_cps_l = [self.lin_cps1(utt_x_cps) for utt_x_cps in utt_cps_l]\n",
    "                utt_cps_l = [self.lin_cps2(utt_x_cps) for utt_x_cps in utt_cps_l]\n",
    "                utt_cps_l = [self.relu(utt_x_cps) for utt_x_cps in utt_cps_l]\n",
    "            cps = torch.stack(tuple(utt_cps_l), dim=1)\n",
    "            cps = self.lstm_cps(cps)[1][0][0]\n",
    "\n",
    "        if action_b:\n",
    "            if lin_layers:\n",
    "                utt_action_l = [self.lin_action1(utt_x_action) for utt_x_action in utt_action_l]\n",
    "                utt_action_l = [self.lin_action2(utt_x_action) for utt_x_action in utt_action_l]\n",
    "                utt_action_l = [self.relu(utt_x_action) for utt_x_action in utt_action_l]\n",
    "            action = torch.stack(tuple(utt_action_l), dim=1)\n",
    "            action = self.lstm_action(action)[1][0][0]\n",
    "\n",
    "        if gamr_b:\n",
    "            if lin_layers:\n",
    "                utt_gamr_l = [self.lin_gamr1(utt_x_gamr) for utt_x_gamr in utt_gamr_l]\n",
    "                utt_gamr_l = [self.lin_gamr2(utt_x_gamr) for utt_x_gamr in utt_gamr_l]\n",
    "                utt_gamr_l = [self.relu(utt_x_gamr) for utt_x_gamr in utt_gamr_l]\n",
    "            gamr = torch.stack(tuple(utt_gamr_l), dim=1)\n",
    "            gamr = self.lstm_gamr(gamr)[1][0][0]\n",
    "\n",
    "        modals = []\n",
    "        if bert_b: modals.append(bert)\n",
    "        if opensmile_b: modals.append(opensmile)\n",
    "        if cps_b: modals.append(cps)\n",
    "        if action_b: modals.append(action)\n",
    "        if gamr_b: modals.append(gamr)\n",
    "\n",
    "\n",
    "        x = torch.hstack(tuple(modals))\n",
    "        x = self.ff1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.ff2(x)\n",
    "        x = self.act2(x)\n",
    "        predict = self.classifier(x)\n",
    "\n",
    "        return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_train(model, total_epochs, lr, train_loader, class_to_eval, lin_layers, bert_b, opensmile_b, cps_b, cps_f_b, action_b, gamr_b, output_size):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    epoch_loss = []\n",
    "    nepochs = 0\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss(reduction='mean').to(device)\n",
    "    if output_size != 1:\n",
    "        criterion = nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "    while nepochs < total_epochs :\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = []\n",
    "        for utt_bert_l, utt_open_l, utt_cps_f_l, utt_cps_i_l, utt_action_l, utt_gamr_l, utt_y_l in train_loader:\n",
    "            utt_cps_l = utt_cps_f_l\n",
    "            if not cps_f_b:\n",
    "                utt_cps_l = utt_cps_i_l\n",
    "            output = model(utt_bert_l.to(device), utt_open_l.to(device), utt_cps_l.to(device), utt_action_l.to(device), utt_gamr_l.to(device), lin_layers, bert_b, opensmile_b, cps_b, cps_f_b, action_b, gamr_b).to(device)\n",
    "            target = utt_y_l[-1].to(device)\n",
    "            if output_size == 1:\n",
    "                target_binary = torch.zeros(target.size()[0], 1).to(device)\n",
    "                for i,t in enumerate(target):\n",
    "                    target_binary[i] = torch.Tensor([t[class_to_eval]])\n",
    "                loss = criterion(torch.sigmoid(output), target_binary)\n",
    "            else:\n",
    "                loss = criterion(output, target)\n",
    "            batch_loss.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        nepochs += 1\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_test(model, test_loader, class_to_eval, lin_layers, bert_b, opensmile_b, cps_b, cps_f_b, action_b, gamr_b, output_size):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        true, pred = None, None\n",
    "        for utt_bert_l, utt_open_l, utt_cps_f_l, utt_cps_i_l, utt_action_l, utt_gamr_l, utt_y_l in test_loader:\n",
    "            utt_cps_l = utt_cps_f_l\n",
    "            if not cps_f_b:\n",
    "                utt_cps_l = utt_cps_i_l\n",
    "            output = model(utt_bert_l.to(device), utt_open_l.to(device), utt_cps_l.to(device), utt_action_l.to(device), utt_gamr_l.to(device), lin_layers, bert_b, opensmile_b, cps_b, cps_f_b, action_b, gamr_b).to(device)\n",
    "            target = utt_y_l[-1].to(device)\n",
    "            if output_size == 1:\n",
    "                pred_tmp = torch.sigmoid(output)\n",
    "                true_binary = torch.zeros(target.size()[0], 1)\n",
    "                for i, t in enumerate(target):\n",
    "                    true_binary[i] = torch.Tensor([t[class_to_eval]])\n",
    "                if true == None:\n",
    "                    true = true_binary\n",
    "                    pred = pred_tmp > 0.5\n",
    "                    pred_probs = pred_tmp\n",
    "\n",
    "                else :\n",
    "                    true = torch.cat((true, true_binary))\n",
    "                    pred = torch.cat((pred, pred_tmp > 0.5))\n",
    "                    pred_probs = torch.cat((pred_probs, pred_tmp))\n",
    "                    \n",
    "            \n",
    "            else:\n",
    "                softmax = torch.nn.Softmax(dim=1)\n",
    "                target_ = torch.clone(target)\n",
    "                true_tmp = target_.cpu().numpy()\n",
    "                preds_tmp = softmax(output).cpu().detach().numpy()\n",
    "\n",
    "                if true == None:\n",
    "                    true = torch.argmax(torch.from_numpy(true_tmp), dim=1)\n",
    "                    pred = torch.argmax(torch.from_numpy(preds_tmp), dim=1)\n",
    "                    pred_probs = torch.tensor(preds_tmp)\n",
    "                else:\n",
    "                    true = torch.cat((true, torch.argmax(torch.from_numpy(true_tmp), dim=1)))\n",
    "                    pred = torch.cat((pred, torch.argmax(torch.from_numpy(preds_tmp), dim=1)))\n",
    "                    pred_probs = torch.cat((pred_probs, torch.tensor(preds_tmp)))\n",
    "        \n",
    "    return true, pred, pred_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_window_size(train_list, window_size):\n",
    "    rec_train_list = []\n",
    "    pad = [[0]*1199, [0]*len(train_list[0][1])]\n",
    "\n",
    "    for utt_id in range(len(train_list)):\n",
    "        aux = []\n",
    "        for i in range(window_size):\n",
    "            if utt_id == i:\n",
    "                for _ in range(window_size-utt_id):\n",
    "                    aux.append(pad)\n",
    "        for i in range(window_size):\n",
    "            if len(aux) == i:\n",
    "                aux.append(train_list[utt_id - window_size + i])\n",
    "        aux.append(train_list[utt_id])\n",
    "        rec_train_list.append(aux)\n",
    "    \n",
    "    return rec_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(window_size):\n",
    "    full_data = []\n",
    "    for group in range(1, 11):\n",
    "        train_datasets = DATA()\n",
    "        for root, dirs,files in (os.walk(os. getcwd())):\n",
    "            if f\"Group_{group:02d}\" in root and \"data\" not in root:\n",
    "                if \"asr\" not in root:\n",
    "                    print(root)\n",
    "                    for file in files:\n",
    "                        read_data(train_datasets, root, file)\n",
    "        train_list = train_datasets.get_datasets()\n",
    "        train_list = [[a+b+c+d+e+f, g] for a,b,c,d,e,f,g in train_list]\n",
    "        rec_train_list = change_window_size(train_list, window_size)\n",
    "        full_data += rec_train_list\n",
    "    random.shuffle(full_data)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/s/chopin/b/grad/benkh/Common Ground/Group_01\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_02\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_03\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_04\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_05\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_06\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_07\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_08\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_09\n",
      "/s/chopin/b/grad/benkh/Common Ground/Group_10\n"
     ]
    }
   ],
   "source": [
    "full_data = get_data(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to remove utterances with no CGA\n",
    "\n",
    "# utt_id = 0\n",
    "# while utt_id  < (len(full_data)):\n",
    "#     if full_data[utt_id][-1][1] == [0, 0, 0, 0, 0, 0, 0, 1]:\n",
    "#         del full_data[utt_id]\n",
    "#     else:\n",
    "#         utt_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "split_size = int(train_split*len(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(full_data)\n",
    "rec_train_list, rec_test_list = full_data[:split_size], full_data[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_train_loader = DataLoader(dataset=rec_dataset(rec_train_list, window_size),batch_size=4,shuffle=False)\n",
    "rec_test_loader = DataLoader(dataset=rec_dataset(rec_test_list, window_size),batch_size=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec_common_ground(\n",
       "  (lin_bert1): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (lin_bert2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lstm_bert): LSTM(256, 256, batch_first=True)\n",
       "  (lin_open1): Linear(in_features=88, out_features=256, bias=True)\n",
       "  (lin_open2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lstm_opensmile): LSTM(256, 256, batch_first=True)\n",
       "  (relu): ReLU()\n",
       "  (lin_cps1): Linear(in_features=3, out_features=256, bias=True)\n",
       "  (lin_cps2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lstm_cps): LSTM(256, 256, batch_first=True)\n",
       "  (lin_action1): Linear(in_features=78, out_features=256, bias=True)\n",
       "  (lin_action2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lstm_action): LSTM(256, 256, batch_first=True)\n",
       "  (lin_gamr1): Linear(in_features=243, out_features=256, bias=True)\n",
       "  (lin_gamr2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lstm_gamr): LSTM(256, 256, batch_first=True)\n",
       "  (ff1): Linear(in_features=1280, out_features=512, bias=True)\n",
       "  (ff2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (act1): Tanh()\n",
       "  (act2): SiLU()\n",
       "  (classifier): Linear(in_features=512, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rec_common_ground(lin_layers=True, bert_b=True, opensmile_b=True, cps_b=True, cps_f_b=True, action_b=True, gamr_b=True, output_size=8)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, epoch_loss = rec_train(model, 2, 0.001, rec_train_loader, 2, True, True, True, True, True, True, True, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(21.1342, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.7819, device='cuda:0', grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred, pred_probs = rec_test(model, rec_test_loader, 2, True, True, True, True, True, True, True, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8692129629629629"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(true.to(\"cpu\"), pred.to(\"cpu\"))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(true.to(\"cpu\"), pred.to(\"cpu\").to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(torch.zeros_like(pred.to(\"cpu\"))+7, pred.to(\"cpu\").to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(torch.zeros_like(pred.to(\"cpu\")), pred_probs.to(\"cpu\").to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = true.cpu()\n",
    "pred = pred.cpu()\n",
    "accuracy = accuracy_score(true, pred)\n",
    "# mean_f1_score = f1_score(true, pred)\n",
    "weighted_f1_score = f1_score(true, pred, average=\"weighted\")\n",
    "# mean_precision = precision_score(true, pred)\n",
    "weighted_precision = precision_score(true, pred, average=\"weighted\")\n",
    "# mean_recall = recall_score(true, pred)\n",
    "weighted_recall = recall_score(true, pred, average=\"weighted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    auroc = roc_auc_score(true, torch.nan_to_num(pred_probs, 0))\n",
    "except:\n",
    "    auroc =  0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8692129629629629\n",
      "0.808394966173604\n",
      "0.7555311749828532\n",
      "0.8692129629629629\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "# print(mean_f1_score)\n",
    "print(weighted_f1_score)\n",
    "# print(mean_precision)\n",
    "print(weighted_precision)\n",
    "# print(mean_recall)\n",
    "print(weighted_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMs = [\"bert-base-uncased\", \"bert-large-uncased\", \"albert\", \"roberta\", \"xlm\"]\n",
    "n_folds = [5] # train test valid\n",
    "window_sizes = [7]\n",
    "lrs = [0.001]\n",
    "output_sizes = [1, 8, 9] # [binary, multinomial without negatives, multinomial with all utterances]\n",
    "bert_b_l = [True, False]\n",
    "opensmile_b_l = [True, False]\n",
    "action_b_l = [True, False]\n",
    "gamr_b_l = [True, False]\n",
    "cps_b_l = [True, False]\n",
    "cps_f_b_l = [True, False]\n",
    "lin_layers_l = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 2\n",
    "epoch_per_step = 1\n",
    "output_size = 1\n",
    "for llm in LLMs:\n",
    "    tokenizer, llm, llm_size = change_llm(LLM)\n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        full_data = get_data(window_size)\n",
    "\n",
    "        for n_fold in n_folds:\n",
    "            print(n_fold)\n",
    "            fold_len = int(np.ceil(len(full_data)/len(n_folds)))\n",
    "            folds = [full_data[x:x+fold_len] for x in range(0, len(full_data), fold_len)]\n",
    "\n",
    "            for class_to_eval in range(7):\n",
    "                for lr in lrs:\n",
    "                    for bert_b in bert_b_l:\n",
    "                        for opensmile_b in opensmile_b_l:\n",
    "                            for action_b in action_b_l:\n",
    "                                for gamr_b in gamr_b_l:\n",
    "                                    for cps_b in cps_b_l:\n",
    "                                        if not (bert_b==opensmile_b==cps_b==action_b==gamr_b==False):\n",
    "                                            cps_f_b = True # Using facets not indicators\n",
    "                                            for lin_layers in lin_layers_l:\n",
    "                                                print(f\"\\n Results for class {class_to_eval}\")\n",
    "                                                for k in range(len(folds)):\n",
    "                                                    train_l = []\n",
    "                                                    for i in range(len(folds)):\n",
    "                                                        if i != k:\n",
    "                                                            train_l += folds[i]\n",
    "                                                    test_l = folds[k]\n",
    "                                                    train_loader = DataLoader(dataset=rec_dataset(train_l),batch_size=16,shuffle=True)\n",
    "                                                    test_loader = DataLoader(dataset=rec_dataset(test_l),batch_size=16,shuffle=True)\n",
    "                                                    \n",
    "                                                    model = rec_common_ground(lin_layers, bert_b, opensmile_b, cps_b, cps_f_b, action_b, gamr_b, output_size)\n",
    "                                                    for epoch in range(int(total_epochs/epoch_per_step)):\n",
    "                                                        model, epoch_loss = rec_train(model, epoch_per_step, lr, train_loader, class_to_eval, lin_layers, bert_b, opensmile_b, cps_b, cps_f_b, action_b, gamr_b, output_size)\n",
    "                                                        true, pred, pred_probs = rec_test(model, test_loader, class_to_eval, lin_layers, bert_b, opensmile_b, cps_b, cps_f_b, action_b, gamr_b, output_size)\n",
    "\n",
    "                                                        true = true.cpu()\n",
    "                                                        pred = pred.cpu()\n",
    "                                                        accuracy = accuracy_score(true, pred)\n",
    "                                                        mean_f1_score = f1_score(true, pred)\n",
    "                                                        weighted_f1_score = f1_score(true, pred, average=\"weighted\")\n",
    "                                                        mean_precision = precision_score(true, pred)\n",
    "                                                        weighted_precision = precision_score(true, pred, average=\"weighted\")\n",
    "                                                        mean_recall = recall_score(true, pred)\n",
    "                                                        weighted_recall = recall_score(true, pred, average=\"weighted\")\n",
    "                                                        try:\n",
    "                                                            auroc = roc_auc_score(true, torch.nan_to_num(pred_probs, 0))\n",
    "                                                        except:\n",
    "                                                            auroc =  0.5\n",
    "\n",
    "\n",
    "                                                        # torch.save(model, f\"save/binary_all_features/{Class_to_eval}_{filt}_{NN_size}_{epochs}_{group_holdout}.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
