{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import shap\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, XLMTokenizer, XLMConfig, XLMModel, \\\n",
    "    AlbertTokenizer, AlbertModel, RobertaTokenizer, RobertaConfig, RobertaModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)',text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = \"bert-base-uncased\"\n",
    "# LLM = \"bert-large-uncased\"\n",
    "# LLM = \"albert\"\n",
    "# LLM = \"roberta\"\n",
    "# LLM = \"xlm\"\n",
    "\n",
    "def change_llm(LLM):\n",
    "\n",
    "    if \"bert-\" in LLM:\n",
    "        tokenizer = BertTokenizer.from_pretrained(LLM)\n",
    "        llm = BertModel.from_pretrained(LLM)\n",
    "\n",
    "\n",
    "    if LLM == \"albert\":\n",
    "        tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "        llm = AlbertModel.from_pretrained('albert-base-v2')\n",
    "\n",
    "    if LLM == \"roberta\":\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "        configuration = RobertaConfig()\n",
    "        llm = RobertaModel(configuration)\n",
    "\n",
    "    if LLM == \"xlm\":\n",
    "        tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-en-2048\")\n",
    "        configuration = XLMConfig()\n",
    "        llm = XLMModel(configuration)\n",
    "\n",
    "\n",
    "    llm.eval()\n",
    "    sentence = \"Paris is a beautiful city\" \n",
    "    tok = tokenizer(sentence)\n",
    "    encoded_layers = llm(torch.Tensor([tok.input_ids]).to(torch.int), attention_mask=torch.Tensor([tok.attention_mask]))\n",
    "    llm_size = (encoded_layers.last_hidden_state)[:, 0, :].size()[1]\n",
    "\n",
    "    return tokenizer, llm, llm_size\n",
    "tokenizer, llm, llm_size = change_llm(LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMs = [\"bert-base-uncased\", \"bert-large-uncased\", \"albert\", \"roberta\", \"xlm\"]\n",
    "for LLM in LLMs:\n",
    "    tokenizer, llm, llm_size = change_llm(LLM)\n",
    "    for root, dirs,files in (os.walk(os. getcwd())):\n",
    "        if \"Group_\" in root:\n",
    "            if \"asr\" not in root: # (update) change to process rows in csv files instead of seperate txt files\n",
    "                df = pd.DataFrame()\n",
    "                for file in files:\n",
    "                    if 'Oracle.csv' in file:\n",
    "                        transcripts = pd.read_csv(root+'/'+file)[\"Transcript\"].fillna(\"\")\n",
    "                        for transc in transcripts:\n",
    "                            tok = tokenizer(transc)\n",
    "                            with torch.no_grad():\n",
    "                                encoded_layers = llm(torch.Tensor([tok.input_ids]).to(torch.int), attention_mask=torch.Tensor([tok.attention_mask]))\n",
    "                            tensor = (encoded_layers.last_hidden_state)[:, 0, :]\n",
    "                            tensor_df = pd.DataFrame(tensor.numpy())\n",
    "                            df = pd.concat((df, tensor_df))\n",
    "                gr = root.find('Group')\n",
    "                group = root[gr:gr+8]\n",
    "                df.to_csv(group+'/'+group+\"_\"+LLM+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv1_lv3 = dict({0:0, 1:0, 2:0, 3:0, 4:0, 5:1, 6:1, 7:1, 8:1, 9:1, 10:1, 11:1, 12:1, 13:2, 14:2, 15:2, 16:2, 17:2, 18:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataset_llm = []\n",
    "        self.dataset_opensmile = []\n",
    "        self.dataset_cps_f = []\n",
    "        self.dataset_cps_i = []\n",
    "        self.targets = []\n",
    "\n",
    "    def openBERT(self, filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        for i in range(len(data)):\n",
    "            self.dataset_llm.append(np.asarray(data.iloc[i]))\n",
    "    \n",
    "    \n",
    "    def openSmile(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        for i in range (data.shape[0]):\n",
    "            # print(f'C:\\\\Users\\\\Bbykitty\\\\OneDrive - Colostate\\\\Research\\\\Initial Observations for Fib Weights\\\\Data\\\\Segment Analysis\\\\{filename[filename.index(\"Group_\"):filename.index(\"Group_\")+8]}\\\\segments_oracle\\\\{filename[filename.index(\"Group_\"):filename.index(\"Group_\")+8]}_'+str(i)+'.wav')\n",
    "            row=data[data['file']==f'C:\\\\Users\\\\bradf\\\\OneDrive - Colostate\\\\Research\\\\Initial Observations for Fib Weights\\\\Data\\\\Segment Analysis\\\\{filename[filename.index(\"Group_\"):filename.index(\"Group_\")+8]}\\\\segments_oracle\\\\{filename[filename.index(\"Group_\"):filename.index(\"Group_\")+8]}_'+str(i)+'.wav']\n",
    "            tensor=np.asarray(row.values[0][3:],dtype=np.float32).tolist()\n",
    "            self.dataset_opensmile.append(tensor)\n",
    "\n",
    "\n",
    "    def openCPS(self, filename):\n",
    "        data = pd.read_csv(filename).fillna(0)\n",
    "        for row in range(data.shape[0]):\n",
    "            cps = data.iloc[row, 10:].fillna(0)\n",
    "            self.dataset_cps_i.append(cps)\n",
    "            cps_f = [0, 0, 0]\n",
    "            for i, c in enumerate(cps):\n",
    "                if c == 1:\n",
    "                    cps_f[lv1_lv3[i]] = 1\n",
    "            self.dataset_cps_f.append(cps_f)\n",
    "        \n",
    "\n",
    "    def openTarget(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        for row in range(data.shape[0]):\n",
    "            target = data.iloc[row, 4:].values.astype(int)\n",
    "            self.targets.append(target)\n",
    "\n",
    "\n",
    "    def get_datasets(self, rand=False):\n",
    "        final_dataset=[]\n",
    "        if len(self.dataset_llm) == 0:\n",
    "            for opensmile, label in zip(self.dataset_opensmile, self.targets):\n",
    "                final_dataset.append([opensmile,label])\n",
    "        if len(self.dataset_opensmile) == 0:\n",
    "            for bert, label in zip(self.dataset_llm, self.targets):\n",
    "                final_dataset.append([bert,label])\n",
    "        if rand:\n",
    "            random.shuffle(final_dataset)\n",
    "        return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataset, root, file, llm=\"bert-base-uncased\"):\n",
    "\n",
    "    if LLM in file:\n",
    "        dataset.openBERT(root+\"/\"+file)\n",
    "    if 'opensmile' in file:\n",
    "        dataset.openSmile(root+\"/\"+file)\n",
    "    elif 'CG.csv' in file:\n",
    "        dataset.openTarget(root+\"/\"+file)\n",
    "    elif 'CPS_Oracle' in file:\n",
    "        dataset.openCPS(root+\"/\"+file)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = DATA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs,files in (os.walk(os. getcwd())):\n",
    "    if \"Group_\" in root:\n",
    "        if \"asr\" not in root:\n",
    "            for file in files:\n",
    "                read_data(train_datasets, root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_datasets.dataset_llm = scaler.fit_transform(train_datasets.dataset_llm).tolist()\n",
    "scaler = MinMaxScaler()\n",
    "train_datasets.dataset_opensmile = scaler.fit_transform(train_datasets.dataset_opensmile).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nlp_dataset(Dataset):\n",
    "    def __init__(self,xy=None):\n",
    "\n",
    "        self.bert_data = torch.from_numpy(np.asarray([el[0] for el in xy],dtype=np.float32))\n",
    "        self.open_data = torch.from_numpy(np.asarray([el[1] for el in xy],dtype=np.float32))\n",
    "        self.y_data = torch.from_numpy(np.asarray([el[2] for el in xy],dtype=np.float32))\n",
    "        self.len=len(self.bert_data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.bert_data[index], self.open_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=nlp_dataset(train_datasets.get_datasets(rand=True)),batch_size=16,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = train_datasets.get_datasets()\n",
    "l = [a+b for a,b,c in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_folds = 3\n",
    "fold_len = int(np.ceil(len(train_datasets.get_datasets())/n_folds))\n",
    "fold_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [train_datasets.get_datasets()[x:x+fold_len] for x in range(0, len(train_datasets.get_datasets()), fold_len)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = train_datasets.get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [[a+b, c] for a,b,c in train_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variable window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_train_list = []\n",
    "pad = [[0]*600, [0]*7]\n",
    "for utt_id in range(len(train_list)):\n",
    "    aux = []\n",
    "    for i in range(window_size):\n",
    "        if utt_id == i:\n",
    "            for _ in range(window_size):\n",
    "                aux.append(pad)\n",
    "    for i in range(window_size):\n",
    "        if len(aux) == i:\n",
    "            aux.append(train_list[utt_id - window_size + i])\n",
    "    aux.append(train_list[utt_id])\n",
    "    rec_train_list.append(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rec_dataset(Dataset):\n",
    "    def __init__(self,xy=None):\n",
    "        self.utt_bert_l = []\n",
    "        self.utt_open_l = []\n",
    "        self.utt_y_l = []\n",
    "\n",
    "        for i in range(window_size+1):\n",
    "            self.utt_bert_l.append(torch.from_numpy(np.asarray([el[i][0][:llm_size] for el in xy],dtype=np.float32)).to(device))\n",
    "            self.utt_open_l.append(torch.from_numpy(np.asarray([el[i][0][llm_size:] for el in xy],dtype=np.float32)).to(device))\n",
    "            self.utt_y_l.append(torch.from_numpy(np.asarray([el[i][1] for el in xy],dtype=np.float32)).to(device))\n",
    "        \n",
    "        self.len=len(self.utt_bert_l[0])\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.utt_bert_l[index], self.utt_open_l[index], self.utt_y_l[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_train_loader = DataLoader(dataset=rec_dataset(rec_train_list),batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rec_common_ground(nn.Module):\n",
    "    def __init__(self, lin_layers=True, bert_b=True, opensmile_b=True, output_size=1):\n",
    "        super(rec_common_ground, self).__init__()\n",
    "        self.lin_bert1 = nn.Linear(llm_size, 256)\n",
    "        self.lin_bert2 = nn.Linear(256, 256)\n",
    "        if not lin_layers:\n",
    "            self.lstm_bert = nn.LSTM(input_size=llm_size, batch_first=True, hidden_size=256)\n",
    "        self.lstm_bert = nn.LSTM(input_size=256, batch_first=True, hidden_size=256)\n",
    "        self.lin_open1 = nn.Linear(88, 256)\n",
    "        self.lin_open2 = nn.Linear(256, 256)\n",
    "        self.lstm_opensmile = nn.LSTM(input_size=256, batch_first=True, hidden_size=256)\n",
    "        self.relu = nn.ReLU()\n",
    "        if not bert_b or not opensmile_b:\n",
    "            self.ff1 = nn.Linear(256, 512)\n",
    "        self.ff1 = nn.Linear(512, 512)\n",
    "        self.ff2 = nn.Linear(512, 512)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.act2 = nn.SiLU()\n",
    "        self.classifier = nn.Linear(512, output_size)\n",
    "\n",
    "    def forward(self, utt_bert_l, utt_open_l, lin_layers=True, bert_b=True, opensmile_b=True):\n",
    "\n",
    "        if bert_b:\n",
    "            if lin_layers:\n",
    "                utt_bert_l = [self.lin_bert1(utt_x_bert) for utt_x_bert in utt_bert_l]\n",
    "                utt_bert_l = [self.lin_bert2(utt_x_bert) for utt_x_bert in utt_bert_l]\n",
    "                utt_bert_l = [self.relu(utt_x_bert) for utt_x_bert in utt_bert_l]\n",
    "            bert = torch.stack(tuple(utt_bert_l), dim=1)\n",
    "            bert = self.lstm_bert(bert)[1][0][0]\n",
    "\n",
    "        if opensmile_b:\n",
    "            if lin_layers:\n",
    "                utt_open_l = [self.lin_open1(utt_x_open) for utt_x_open in utt_open_l]\n",
    "                utt_open_l = [self.lin_open2(utt_x_open) for utt_x_open in utt_open_l]\n",
    "                utt_open_l = [self.relu(utt_x_open) for utt_x_open in utt_open_l]\n",
    "            opensmile = torch.stack(tuple(utt_open_l), dim=1)\n",
    "            opensmile = self.lstm_opensmile(opensmile)[1][0][0]\n",
    "\n",
    "        if bert_b and opensmile_b:\n",
    "            x = torch.hstack((bert, opensmile))\n",
    "        if not bert_b:\n",
    "            x = opensmile\n",
    "        if not opensmile_b:\n",
    "            x = bert\n",
    "        x = self.ff1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.ff2(x)\n",
    "        x = self.act2(x)\n",
    "        predict = self.classifier(x)\n",
    "\n",
    "        return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_train(model, total_epochs, lr, train_iterator, class_to_eval, lin_layers, bert_b, opensmile_b, output_size):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    epoch_loss = []\n",
    "    nepochs = 0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss(reduction='mean').to(device)\n",
    "    if output_size != 1:\n",
    "        criterion = nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "    while nepochs < total_epochs :\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = []\n",
    "        for batch_idx, (utt_bert_l, utt_open_l, utt_y_l) in enumerate(train_iterator):\n",
    "            output = model(utt_bert_l, utt_open_l, lin_layers, bert_b, opensmile_b, output_size)\n",
    "            target = utt_y_l[-1]\n",
    "            if output_size == 1:\n",
    "                target_binary = torch.zeros(target.size()[0], 1).to(device)\n",
    "                for i,t in enumerate(target):\n",
    "                    target_binary[i] = torch.Tensor([t[class_to_eval]])\n",
    "                loss = criterion(torch.sigmoid(output).to(device), target_binary)\n",
    "            else:\n",
    "                loss = criterion(output, target)\n",
    "            batch_loss.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        nepochs += 1\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_test(model, test_iterator, class_to_eval,   lin_layers, bert_b, opensmile_b, output_size):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        true, pred = None, None\n",
    "        for batch_idx, (utt_bert_l, utt_open_l, utt_y_l) in enumerate(test_iterator):\n",
    "            output = model(utt_bert_l, utt_open_l, lin_layers, bert_b, opensmile_b, output_size)\n",
    "            pred_tmp = torch.sigmoid(output)\n",
    "            target = utt_y_l[-1]\n",
    "            true_binary = torch.zeros(target.size()[0], 1)\n",
    "            for i, t in enumerate(target):\n",
    "                true_binary[i] = torch.Tensor([t[class_to_eval]])\n",
    "            \n",
    "            if true == None:\n",
    "                true = true_binary\n",
    "                pred = pred_tmp > 0.5\n",
    "                pred_probs = pred_tmp\n",
    "\n",
    "            else :\n",
    "                true = torch.cat((true, true_binary))\n",
    "                pred = torch.cat((pred, pred_tmp > 0.5))\n",
    "                pred_probs = torch.cat((pred_probs, pred_tmp))\n",
    "    return true, pred, pred_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMs = [\"bert-base-uncased\", \"bert-large-uncased\", \"albert\", \"roberta\", \"xlm\"]\n",
    "n_folds = [5, 6, 7] # train test valid\n",
    "window_sizes = [1, 3, 5, 7, 9]\n",
    "lrs = [0.01, 0.001, 0.0001]\n",
    "output_sizes = [1, 8, 9] # [binary, multinomial without negatives, multinomial with all utterances]\n",
    "bert_b = [True, False]\n",
    "opensmile_b = [True, False]\n",
    "action_b = [True, False]\n",
    "gamr_b = [True, False]\n",
    "objects_b = [True, False]\n",
    "cps_b = [True, False]\n",
    "lin_layers = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for class 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9505766062602965\n",
      "0.9703459637561779\n",
      "0.9686468646864687\n",
      "Results for class 1\n",
      "0.957166392092257\n",
      "0.02800658978583196\n",
      "0.03135313531353135\n",
      "Results for class 2\n",
      "0.9390444810543658\n",
      "0.957166392092257\n",
      "0.9455445544554455\n",
      "Results for class 3\n",
      "0.9604612850082372\n",
      "0.9686985172981878\n",
      "0.971947194719472\n",
      "Results for class 4\n",
      "0.9901153212520593\n",
      "0.9950576606260296\n",
      "0.9867986798679867\n",
      "Results for class 5\n",
      "0.9934102141680395\n",
      "0.9950576606260296\n",
      "0.9867986798679867\n"
     ]
    }
   ],
   "source": [
    "tokenizer, llm, llm_size = change_llm(LLM)\n",
    "fold_len = int(np.ceil(len(train_datasets.get_datasets())/n_folds))\n",
    "folds = [train_datasets.get_datasets()[x:x+fold_len] for x in range(0, len(train_datasets.get_datasets()), fold_len)]\n",
    "\n",
    "for class_to_eval in range(6):\n",
    "    print(f\"Results for class {class_to_eval}\")\n",
    "    for k in range(len(folds)):\n",
    "        train_l = []\n",
    "        for i in range(len(folds)):\n",
    "            if i != k:\n",
    "                train_l += folds[i]\n",
    "        test_l = folds[k]\n",
    "        train_loader = DataLoader(dataset=rec_dataset(train_l),batch_size=16,shuffle=False)\n",
    "        test_loader = DataLoader(dataset=rec_dataset(test_l),batch_size=16,shuffle=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        model = rec_common_ground(lin_layers, bert_b, opensmile_b, output_size).to(device)\n",
    "        rec_train(model, 60, train_loader, class_to_eval)\n",
    "        true, pred, pred_probs = rec_test(model, test_loader, class_to_eval)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # try:\n",
    "        #     auroc = roc_auc_score(true, torch.nan_to_num(pred_probs, 0.5))\n",
    "        # except:\n",
    "        #     auroc =  0.5\n",
    "        # print(auroc)\n",
    "        accuracy = accuracy_score(true.to(\"cpu\"), pred.to(\"cpu\"))\n",
    "        print(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "        # torch.save(model, f\"save/binary_all_features/{Class_to_eval}_{filt}_{NN_size}_{epochs}_{group_holdout}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rec_common_ground()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec_common_ground(\n",
       "  (lin_bert1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (lin_bert2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lstm_bert): LSTM(256, 256, batch_first=True)\n",
       "  (lin_open1): Linear(in_features=88, out_features=256, bias=True)\n",
       "  (lin_open2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lstm_opensmile): LSTM(256, 256, batch_first=True)\n",
       "  (relu): ReLU()\n",
       "  (ff1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (ff2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (act1): Tanh()\n",
       "  (act2): SiLU()\n",
       "  (classifier): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss = rec_train(model, 120, rec_train_loader, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-6.2792e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-6.2792e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(-5.8867e+08, device='cuda:0', grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
